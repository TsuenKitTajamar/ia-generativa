{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.55.3)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.1)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\andyl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading tiktoken-0.8.0-cp313-cp313-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 883.8/883.8 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, regex, charset-normalizer, requests, tiktoken\n",
      "Successfully installed charset-normalizer-3.4.1 regex-2024.11.6 requests-2.32.3 tiktoken-0.8.0 urllib3-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai tiktoken python-dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòç,‚ú®,üëè,üéâ,üöÄ\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot classification\n",
    "system_prompt =\"\"\"Predict up to 5 emojis as a response to a text chat message. The output\n",
    "should only include emojis.\n",
    "\n",
    "input: The new visual design is blowing my mind ü§Ø\n",
    "output: ‚ûï,üíò, ‚ù§‚Äçüî•\n",
    "\n",
    "input: Well that looks great regardless\n",
    "output: ‚ù§Ô∏è,ü™Ñ\n",
    "\n",
    "input: Unfortunately this won't work\n",
    "output: üíî,üòî\n",
    "\n",
    "input: sounds good, I'll look into that\n",
    "output: üôè,üëç\n",
    "\n",
    "input: 10hr cut of jeff goldblum laughing URL\n",
    "output: üòÇ,üíÄ,‚ö∞Ô∏è\n",
    "\"\"\"\n",
    "user_prompt = \"The new user interface is amazing!\"\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages = [{\"role\":\"system\", \"content\":system_prompt},\n",
    "                {\"role\":\"user\",\"content\": user_prompt,}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Best Practices\n",
    "\n",
    "## Write clear instructions\n",
    "\n",
    "Examples:\n",
    "\n",
    "-----------------------\n",
    "Prompt:\n",
    "\n",
    "Write code to calculate the Fibonacci sequence.\n",
    "\n",
    "Better:\n",
    "\n",
    "Write a TypeScript function to efficiently calculate the Fibonacci sequence. Comment the code liberally to explain what each piece does and why it's written that way.\n",
    "\n",
    "----------------------\n",
    "\n",
    "Prompt:\n",
    "\n",
    "Summarize the meeting notes.\n",
    "\n",
    "Better:\n",
    "\n",
    "Summarize the meeting notes in a single paragraph. Then write a markdown list of the speakers and each of their key points. Finally, list the next steps or action items suggested by the speakers, if any.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role Playing\n",
    "\n",
    "Examples:\n",
    "\n",
    "-----------------------\n",
    "\n",
    "System Message: When I ask for help to write something, you will reply with a document that contains at least one joke or playful comment in every paragraph.\n",
    "\n",
    "----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment input text\n",
    "\n",
    "Examples:\n",
    "\n",
    "------------------------\n",
    "\n",
    "user message: Summarize the text delimited by triple quotes with a haiku.\n",
    "\n",
    "\"\"\"insert text here\"\"\"\n",
    "\n",
    "------------------------\n",
    "\n",
    "system message: You will be provided with a pair of articles (delimited with XML tags) about the same topic. First summarize the arguments of each article. Then indicate which of them makes a better argument and explain why.\n",
    "\n",
    "user message: \n",
    "\n",
    "\\<article> insert first article here \\</article>\n",
    "\n",
    "\\<article> insert second article here \\</article>\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain steps and processes to complete a task\n",
    "\n",
    "Examples:\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "System Message:\n",
    "Use the following step-by-step instructions to respond to user inputs.\n",
    "\n",
    "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence with a prefix that says \"Summary: \".\n",
    "\n",
    "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Clasificaci√≥n de Emojis con Zero-shot\n",
    "Enunciado:\n",
    "Dado el siguiente texto, predice hasta 5 emojis que mejor representen la emoci√≥n o el tema del mensaje. Usa el modelo de Zero-shot para hacer la clasificaci√≥n.\n",
    "\n",
    "Texto: \"Estoy tan feliz que no puedo dejar de sonre√≠r.\"\n",
    "\n",
    "Resultado esperado: üòÑ,üòä,‚ú®,üåû,‚ù§Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòäüéâüíñüòÅüåü\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"Dado el siguiente texto, predice hasta 5 emojis que mejor representen la emoci√≥n o el tema del mensaje. Usa el modelo de Zero-shot para hacer la clasificaci√≥n.\"\n",
    "user_prompt = \"Estoy tan feliz que no puedo dejar de sonre√≠r.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages = [{\"role\":\"system\", \"content\":system_prompt},\n",
    "                {\"role\":\"user\",\"content\": user_prompt,}])\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Traducci√≥n de Resumen\n",
    "Enunciado:\n",
    "El siguiente texto es una transcripci√≥n de una reuni√≥n. Res√∫melo en una sola oraci√≥n, luego traduce ese resumen al ingl√©s.\n",
    "\n",
    "Texto:\n",
    "\"\"\"Hoy discutimos sobre la necesidad de mejorar la interfaz de usuario en el sitio web. Los participantes estuvieron de acuerdo en que se debe hacer m√°s intuitiva y accesible, especialmente para usuarios mayores. Tambi√©n se mencion√≥ la importancia de agregar soporte multiling√ºe.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Se lleg√≥ a un consenso sobre la necesidad de mejorar la interfaz de usuario del sitio web para que sea m√°s intuitiva y accesible, especialmente para usuarios mayores, as√≠ como la inclusi√≥n de soporte multiling√ºe.\n",
      "Translation: A consensus was reached on the need to improve the website's user interface to make it more intuitive and accessible, especially for older users, as well as the inclusion of multilingual support.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"El siguiente texto es una transcripci√≥n de una reuni√≥n. Res√∫melo en una sola oraci√≥n\"\n",
    "user_prompt = \"\"\"Hoy discutimos sobre la necesidad de mejorar la interfaz de usuario en el sitio web. Los participantes estuvieron de acuerdo en que se debe hacer m√°s intuitiva y accesible, especialmente para usuarios mayores. Tambi√©n se mencion√≥ la importancia de agregar soporte multiling√ºe.\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [{\"role\":\"system\", \"content\":system_prompt},\n",
    "                {\"role\":\"user\",\"content\": user_prompt}])\n",
    "summary = response.choices[0].message.content\n",
    "print(f\"Summary: {summary}\")\n",
    "\n",
    "# Traducci√≥n al ingl√©s\n",
    "translation_prompt = f\"Traduce el siguiente resumen al Ingles: {summary}\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [{\"role\":\"system\", \"content\": \"Eres un traductor\"},\n",
    "                {\"role\":\"user\",\"content\": translation_prompt}])\n",
    "print(f\"Translation: {response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de salida:\n",
    "\n",
    "Summary: Se discuti√≥ la necesidad de mejorar la interfaz de usuario del sitio web para que sea m√°s intuitiva y accesible, especialmente para usuarios mayores, y se destac√≥ la importancia de incluir soporte multiling√ºe.  \n",
    "Today we discussed the need to improve the website's user interface to make it more intuitive and accessible, especially for older users, and emphasized the importance of adding multilingual support.\n",
    "Translation: The following summary is translated into English: \n",
    "\n",
    "\"We discussed the need to improve the website's user interface to make it more intuitive and accessible, especially for older users, and emphasized the importance of including multilingual support.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Respuesta Autom√°tica con Role-playing\n",
    "Enunciado:\n",
    "Configura un modelo para responder a una solicitud de escritura, haciendo que la respuesta contenga un toque de humor. Usa la siguiente solicitud como ejemplo.\n",
    "\n",
    "Solicitud:\n",
    "\"Escribe una carta formal solicitando d√≠as de vacaciones.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada:**\n",
    "\n",
    "[Tu nombre]  \n",
    "[Tu direcci√≥n]  \n",
    "[Ciudad, Estado, C√≥digo Postal]  \n",
    "[Correo electr√≥nico]  \n",
    "[Tel√©fono]  \n",
    "[Fecha]  \n",
    "\n",
    "[Nombre del jefe o supervisor]  \n",
    "[Nombre de la empresa]  \n",
    "[Direcci√≥n de la empresa]  \n",
    "[Ciudad, Estado, C√≥digo Postal]  \n",
    "\n",
    "Estimado/a [Nombre del jefe o supervisor]:\n",
    "\n",
    "Espero que este mensaje lo/a encuentre en un buen estado de √°nimo y que el caf√© de la ma√±ana a√∫n est√© dando su efecto. Me dirijo a usted para solicitar formalmente unos d√≠as de vacaciones debido a la necesidad de recargar pilas y asegurarme de que mi creatividad no se convierta en un documento en blanco. Despu√©s de todo, un buen descanso es tan esencial como un buen chiste para iniciar la jornada, ¬øverdad?\n",
    "\n",
    "Me gustar√≠a solicitar [n√∫mero de d√≠as] d√≠as de vacaciones, del [fecha de inicio] al [fecha de finalizaci√≥n]. Estoy seguro/a de que puedo entregar todas mis responsabilidades y proyectos antes de esta fecha, para que el equipo no se vea afectado. Prometo no dejar una nota que diga ‚ÄúEn caso de emergencia, llame a mi gato‚Äù, ¬°aunque s√© que muchos lo har√≠an por gracia!\n",
    "\n",
    "Agradezco de antemano su comprensi√≥n y apoyo en esta solicitud. Estoy dispuesto/a a discutir cualquier detalle adicional y a asegurarme de que la transici√≥n sea lo m√°s fluida posible. Al fin y al cabo, no quiero que mis colegas piensen que huyo del trabajo, aunque una playa y un c√≥ctel pueden sonar bastante tentadores.\n",
    "\n",
    "Quedo a la espera de su pronta respuesta. ¬°Prometo volver con muchas historias, y quiz√°s algunos souvenirs divertidos (o un sandalia como souvenir) para compartir!\n",
    "\n",
    "Atentamente,  \n",
    "[Tu nombre]  \n",
    "[Tu puesto]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tu Nombre]  \n",
      "[Tu Direcci√≥n]  \n",
      "[Ciudad, Estado, C√≥digo Postal]  \n",
      "[Tu Correo Electr√≥nico]  \n",
      "[Tu Tel√©fono]  \n",
      "[Fecha]  \n",
      "\n",
      "[Nombre del Jefe]  \n",
      "[Nombre de la Empresa]  \n",
      "[Direcci√≥n de la Empresa]  \n",
      "[Ciudad, Estado, C√≥digo Postal]  \n",
      "\n",
      "Estimado/a [Nombre del Jefe]:\n",
      "\n",
      "Espero que este mensaje lo encuentre bien y de buen humor. ¬°Si no es as√≠, puedo ofrecerte una broma sobre por qu√© los p√°jaros no usan Facebook... porque ya tienen Twitter! Pero, pasando a lo que realmente importa, me gustar√≠a solicitar formalmente unos d√≠as de vacaciones.\n",
      "\n",
      "Conforme a las pol√≠ticas de la empresa, quisiera solicitar [n√∫mero de d√≠as] d√≠as de vacaciones desde el [fecha de inicio] hasta el [fecha de finalizaci√≥n]. La raz√≥n de mi solicitud es que, despu√©s de un tiempo intensivo de trabajo, es importante recargar energ√≠as... como cuando se resetea el WiFi, ¬°es un verdadero salvavidas! Estoy seguro/a de que regresar√© con m√°s motivaci√≥n y un par de an√©cdotas graciosas para compartir.\n",
      "\n",
      "Durante mi ausencia, me asegurar√© de que todas mis responsabilidades est√©n completamente cubiertas. He puesto en marcha un plan para que [Nombre del Compa√±ero/a] se encargue de mis tareas de manera temporal. No te preocupes, no le voy a pagar con galletas, ¬°pero quiz√°s un caf√© le gustar√≠a! Estoy convencido/a de que el equipo seguir√° funcionando sin problemas y podr√© desconectarme sabiendo que todo est√° en buenas manos.\n",
      "\n",
      "Agradezco de antemano tu comprensi√≥n y apoyo. Si necesitas discutir este tema o tienes alguna pregunta, estoy a tu disposici√≥n‚Ä¶ y tambi√©n a la del humor, porque siempre es mejor re√≠rse en el trabajo, ¬°aunque a veces nuestras impresoras parezcan tener un sentido del humor m√°s oscuro!\n",
      "\n",
      "Espero tu respuesta y te agradezco mucho tu atenci√≥n.\n",
      "\n",
      "Saludos cordiales,  \n",
      "\n",
      "[Tu Nombre]  \n",
      "[Tu Cargo]  \n",
      "[Tu Departamento]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"Cuando te pida ayuda para escribir algo, me responder√°s con un documento que contenga al menos un chiste o comentario gracioso en cada p√°rrafo.\"\n",
    "user_prompt = \"Escribe una carta formal solicitando d√≠as de vacaciones.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: carta con broma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Segmentaci√≥n de Texto\n",
    "Enunciado:\n",
    "Segmenta un texto delimitado por comillas triples y luego trad√∫celo a otro idioma (por ejemplo, ingl√©s). Aplica el siguiente formato de entrada de texto y muestra c√≥mo lo har√≠as.\n",
    "\n",
    "Texto de Entrada:\n",
    "\"\"\"Hoy es un buen d√≠a para aprender nuevas cosas y mejorar nuestras habilidades. ¬°El futuro est√° lleno de oportunidades!\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de salida:\n",
    "\n",
    "Summary: Hoy es un buen d√≠a para aprender y mejorar habilidades, ya que el futuro est√° lleno de oportunidades.  \n",
    "Translation: Today is a good day to learn and improve skills, as the future is full of opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen: Hoy es un excelente momento para adquirir conocimientos y desarrollar habilidades, ya que el futuro ofrece muchas oportunidades.\n",
      "\n",
      "Translation: Today is a great time to acquire knowledge and develop skills, as the future offers many opportunities.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"Resume el texto delimitado por comillas triples y escribe la traducci√≥n en ingl√©s.\"\n",
    "\n",
    "user_prompt = \"\"\"Hoy es un buen d√≠a para aprender nuevas cosas y mejorar nuestras habilidades. ¬°El futuro est√° lleno de oportunidades!\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Salida esperada: resumen en espa√±ol e ingl√©s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Predicci√≥n de Emojis con Zero-shot\n",
    "Enunciado:\n",
    "Realiza una clasificaci√≥n Zero-shot utilizando el modelo y predice hasta 5 emojis para el siguiente mensaje:\n",
    "\n",
    "Texto de entrada:\n",
    "\"Estoy muy cansado, pero contento con el trabajo que he hecho.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª‚ú®üòåüí™üåü\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"Predice hasta 5 emojis como respuesta a un mensaje de chat. La salida debe solo incluir emojis.\n",
    "\"\"\"\n",
    "user_prompt = \"1.Estoy muy cansado, pero contento con el trabajo que he hecho. \\\\n\\\\\n",
    "2.Estoy contento y motivado estudiando IA. \"\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: \"üòÖ,üí™,üëå\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Predicci√≥n de Emojis con Few-shot Learning\n",
    "\n",
    "Enunciado:\n",
    "\n",
    "En este ejercicio utilizar√°s Few-shot learning con roles (system, user, assistant) para predecir emojis. En Few-shot learning, proporcionamos ejemplos espec√≠ficos de interacciones para que el modelo aprenda a generalizar la tarea con pocos ejemplos.\n",
    "\n",
    "Dado un conjunto de ejemplos de interacciones entre un usuario y un asistente, utiliza el modelo para predecir hasta 5 emojis para el siguiente mensaje:\n",
    "\n",
    "Mensaje: \"Estoy muy cansado, pero contento con el trabajo que he hecho.\"\n",
    "\n",
    "Devuelve solo los emojis, separados por comas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòå,üíº,üëè,üò¥\n"
     ]
    }
   ],
   "source": [
    "# Definir el prompt con Few-shot utilizando m√∫ltiples roles\n",
    "few_shot_prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant that predicts emojis based on user text.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Estoy muy feliz con mi nuevo trabajo.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üòä,üéâ,üíº,üí™\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"No me siento bien, tengo dolor de cabeza.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üòû,ü§ï,üíî\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Hoy es un d√≠a incre√≠ble para correr al aire libre.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üèÉ‚Äç‚ôÇÔ∏è,üå≥,üåû,üí®\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Acabo de terminar de ver una pel√≠cula emocionante.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üé¨,üëè,üò±,‚ù§Ô∏è\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Voy a dormir temprano, me siento agotado.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üò¥,üõèÔ∏è,üò¥\"},\n",
    "    \n",
    "    # Ahora pedimos la predicci√≥n para el nuevo mensaje\n",
    "    {\"role\": \"user\", \"content\": \"Estoy muy cansado, pero contento con el trabajo que he hecho.\"},\n",
    "]\n",
    "\n",
    "# Llamada a la API para obtener la predicci√≥n de emojis\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=few_shot_prompt\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: \"üòÖ,üí™,üëå\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
