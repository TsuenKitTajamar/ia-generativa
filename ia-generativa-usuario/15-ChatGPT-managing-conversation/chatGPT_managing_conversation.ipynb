{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing conversation history with the ChatGPT model\n",
    "This sample notebook demonstrates a couple of simple patterns you can use for managing the prompts and conversation history with the ChatGPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (1.60.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.60.2-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.60.2-py3-none-any.whl (456 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.60.1\n",
      "    Uninstalling openai-1.60.1:\n",
      "      Successfully uninstalled openai-1.60.1\n",
      "Successfully installed openai-1.60.2\n"
     ]
    }
   ],
   "source": [
    "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "# please make sure you have installed required libraries via pip install -r requirements.txt\n",
    "import os, dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Setting up the deployment name\n",
    "deployment_name = \"gpt-4o-mini\"\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "# This is the value of the endpoint for your Azure OpenAI resource\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "# Currently OPENAI API have the following versions available: https://learn.microsoft.com/azure/ai-services/openai/reference\n",
    "api_version = \"2024-07-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = azure_endpoint,\n",
    "  api_key = api_key,\n",
    "  api_version = \"2024-08-01-preview\"  # This API version or later is required to access seed/events/checkpoint features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Create the system message for ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Define helper functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alumno_ai\\documents\\iag\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages, model_name, max_response_tokens=500, temperature=0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        max_tokens=max_response_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Start the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "user_message = \"I want to write a blog post about the impact of AI on the future of work.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER]\n",
      "Hello, how are you?\n",
      "\n",
      "[ASSISTANT]\n",
      "I'm good, thank you! How can I assist you today?\n",
      "\n",
      "[USER]\n",
      "Can you help me with a Python problem?\n",
      "\n",
      "[ASSISTANT]\n",
      "Of course! Please tell me more about the problem you're facing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm good, thank you! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you help me with a Python problem?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Of course! Please tell me more about the problem you're facing.\"}\n",
    "]\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 65\n"
     ]
    }
   ],
   "source": [
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER]\n",
      "Hello, how are you?\n",
      "\n",
      "[ASSISTANT]\n",
      "I'm good, thank you! How can I assist you today?\n",
      "\n",
      "[USER]\n",
      "Can you help me with a Python problem?\n",
      "\n",
      "[ASSISTANT]\n",
      "Of course! Please tell me more about the problem you're facing.\n",
      "\n",
      "[ASSISTANT]\n",
      "Of course! Please let me know what specific Python problem you're working on, and I'll do my best to help you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_response_tokens = 100\n",
    "\n",
    "response = send_message(messages, deployment_name, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Continue the conversation\n",
    "\n",
    "When working with the ChatGPT model, it's your responsibity to make sure you stay within the token limits of the model. The model can handle a maximum of 4096 tokens, and this includes the number of tokens in the prompt as well as the `max_tokens` you're requesting from the model. If you exceed these limits, the model will return an error.\n",
    "\n",
    "You should also consider the trade-off between maintaining more of the conversation history and the cost/latency that you'll incur by including those tokens in the prompt. Shorter prompts are cheaper and faster. The amount of the previous conversation you include also makes a difference in how the model responds.\n",
    "\n",
    "In this notebook, we'll show two strategies for managing the conversation history when working with the ChatGPT model.\n",
    "- Option 1: Keep the conversation within a given token limit\n",
    "- Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Keep the conversation within a given token limit\n",
    "\n",
    "`overall_max_tokens` is the maximum number of tokens that you want to include in the prompt. Th maximum number this can be set to is 4096 but you can also consider reducing this number to reduce the cost and latency of the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_max_tokens = 1096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 118\n",
      "[USER]\n",
      "Hello, how are you?\n",
      "\n",
      "[ASSISTANT]\n",
      "I'm good, thank you! How can I assist you today?\n",
      "\n",
      "[USER]\n",
      "Can you help me with a Python problem?\n",
      "\n",
      "[ASSISTANT]\n",
      "Of course! Please tell me more about the problem you're facing.\n",
      "\n",
      "[ASSISTANT]\n",
      "Of course! Please let me know what specific Python problem you're working on, and I'll do my best to help you.\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "That sounds great! If you're writing a blog post aimed at business leaders in the tech industry, you'll want to consider topics that are relevant and valuable to them. Here are a few ideas you could explore:\n",
      "\n",
      "### Potential Blog Post Topics:\n",
      "\n",
      "1. **The Future of Work in Tech:** Explore how remote and hybrid work models are shaping the tech industry and what leaders should consider when adapting their strategies.\n",
      "\n",
      "2. **Leveraging AI for Business Growth:** Discuss how artificial intelligence can be integrated into business processes to improve efficiency, enhance customer experience, and drive innovation.\n",
      "\n",
      "3. **Technology and Sustainability:** Examine how tech companies can adopt sustainable practices and contribute to environmental stewardship without sacrificing growth.\n",
      "\n",
      "4. **Cybersecurity in a Digital World:** Provide insights on the importance of cybersecurity measures in the tech industry and how leaders can protect their organizations from potential threats.\n",
      "\n",
      "5. **Diversity and Inclusion in Tech Leadership:** Talk about the importance of having diverse leadership teams in tech and practical steps that business leaders can take to promote inclusivity.\n",
      "\n",
      "6. **Navigating Digital Transformation:** Share strategies on how tech companies can successfully navigate digital transformation, including investing in new technologies and changing company culture.\n",
      "\n",
      "7. **Data-Driven Decision Making:** Discuss how leveraging data analytics can help business leaders make informed decisions and drive organizational success.\n",
      "\n",
      "8. **Emerging Technologies to Watch:** Highlight emerging technologies that have the potential to disrupt the tech industry, such as quantum computing, blockchain, or biotechnology.\n",
      "\n",
      "### Writing Tips:\n",
      "\n",
      "- **Use Data and Case Studies:** Business leaders value data-driven insights. Incorporate relevant statistics, case studies, or examples from successful companies in the tech industry.\n",
      "\n",
      "- **Be Solution-Oriented:** Focus on practical advice and strategies that leaders can implement in their organizations.\n",
      "\n",
      "- **Keep It Engaging:** Use a conversational tone and break up the content with subheadings, bullet points, and visuals to make it easier to read.\n",
      "\n",
      "- **Include a Call to Action:** Encourage leaders to engage with the content further, whether through comments, sharing their experiences, or exploring additional resources.\n",
      "\n",
      "Let me know if you need help with a specific aspect of the blog post, such as an outline, writing tips, or research!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"The target audience for the blog post should be business leaders working in the tech industry.\"\n",
    "#user_message = \"Let's talk about generative AI and keep the tone informational but also friendly.\"\n",
    "#user_message = \"Show me a few more examples\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")\n",
    "\n",
    "# remove first message while over the token limit\n",
    "while token_count > prompt_max_tokens:\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = send_message(messages, deployment_name)\n",
    "\n",
    "#Append assistance response \n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_messages = 10\n",
    "\n",
    "overall_max_tokens = 4096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER]\n",
      "What are the current trends in the tech stock market?\n",
      "\n",
      "[ASSISTANT]\n",
      "As of my last knowledge update in October 2023, I can provide some general trends that have been observed in the tech stock market leading up to that point. However, for the most current insights, I recommend checking real-time financial news and stock market analysis. Here are some notable trends that were observed:\n",
      "\n",
      "1. **Artificial Intelligence (AI) Boom**: Companies developing AI technologies, particularly those involved in machine learning, natural language processing, and generative AI, saw significant increases in investment and stock prices. Major players like NVIDIA and Microsoft, which have been heavily involved in AI, benefited greatly.\n",
      "\n",
      "2. **Cloud Computing Growth**: Cloud services continued to be a strong driver of growth for tech companies. Firms that offer cloud infrastructure and services (like Amazon AWS, Microsoft Azure, and Google Cloud) have been performing well.\n",
      "\n",
      "3. **Increased Focus on Cybersecurity**: With the rising threats of cyberattacks, cybersecurity stocks gained attention as businesses and governments invested more in protecting their digital assets.\n",
      "\n",
      "4. **Regulatory Scrutiny**: Big Tech faced ongoing scrutiny from regulators regarding antitrust issues, privacy concerns, and data security. This uncertainty has sometimes led to volatility in the share prices of major tech firms.\n",
      "\n",
      "5. **Sustainability and ESG Investing**: Companies emphasizing environmental, social, and governance (ESG) factors have attracted more investment. Tech companies that demonstrate commitment to sustainability were increasingly favored by investors.\n",
      "\n",
      "6. **Valuation Corrections**: After a boom period, some tech stocks went through corrections as investors reassessed valuations—particularly for growth stocks that were trading at very high price-to-earnings ratios.\n",
      "\n",
      "7. **Interest Rate Impact**: Tech stocks are particularly sensitive to interest rate changes. As central banks adjusted interest rates to combat inflation, growth tech stocks experienced volatility in response to changing borrowing costs.\n",
      "\n",
      "8. **Increased M&A Activity**: There was a notable trend of mergers and acquisitions as companies sought to bolster their technology portfolios and enhance competitive advantages.\n",
      "\n",
      "9. **Remote Work Technologies**: Companies that provide tools and solutions for remote work continued to see growth, even as hybrid work models became standard.\n",
      "\n",
      "Always remember that market conditions can change rapidly, so staying updated with current news, analyses, and expert commentary is critical for making informed decisions.\n",
      "\n",
      "[USER]\n",
      "Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\n",
      "\n",
      "[USER]\n",
      "### Embracing Generative AI: A Strategic Opportunity for Business Leaders\n",
      "\n",
      "As business leaders with a foundational understanding of technology, the rapid rise of generative AI presents not just challenges, but immense opportunities for innovation and growth. As organizations increasingly adopt artificial intelligence, understanding the strategic implications of generative AI is crucial.\n",
      "\n",
      "#### What is Generative AI?\n",
      "\n",
      "Generative AI encompasses models and systems that can create new content—be it text, images, videos, or even code—based on the data they\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "while len(messages) > max_messages:\n",
    "    messages.pop(0)\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "while token_count > prompt_max_tokens:\n",
    "    # remove first message from messages\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = send_message(messages, deployment_name, max_response_tokens)\n",
    "\n",
    "#Append assistant response\n",
    "messages.append({\"role\": \"user\", \"content\": response})\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Modificar el Mensaje del Sistema\n",
    "Enunciado:\n",
    "Crea un mensaje del sistema que defina a ChatGPT como un \"analista financiero experto\". Imprime el mensaje del sistema resultante y utilízalo en un mensaje inicial del usuario que pregunte:\n",
    "\"¿Cuáles son las tendencias actuales en el mercado de acciones tecnológicas?\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a financial analyst expert.\n",
      "[USER]\n",
      "What are the current trends in the tech stock market?\n",
      "\n",
      "[ASSISTANT]\n",
      "As of my last knowledge update in October 2023, I can provide some general trends that have been observed in the tech stock market leading up to that point. However, for the most current insights, I recommend checking real-time financial news and stock market analysis. Here are some notable trends that were observed:\n",
      "\n",
      "1. **Artificial Intelligence (AI) Boom**: Companies developing AI technologies, particularly those involved in machine learning, natural language processing, and generative AI, saw significant increases in investment and stock prices. Major players like NVIDIA and Microsoft, which have been heavily involved in AI, benefited greatly.\n",
      "\n",
      "2. **Cloud Computing Growth**: Cloud services continued to be a strong driver of growth for tech companies. Firms that offer cloud infrastructure and services (like Amazon AWS, Microsoft Azure, and Google Cloud) have been performing well.\n",
      "\n",
      "3. **Increased Focus on Cybersecurity**: With the rising threats of cyberattacks, cybersecurity stocks gained attention as businesses and governments invested more in protecting their digital assets.\n",
      "\n",
      "4. **Regulatory Scrutiny**: Big Tech faced ongoing scrutiny from regulators regarding antitrust issues, privacy concerns, and data security. This uncertainty has sometimes led to volatility in the share prices of major tech firms.\n",
      "\n",
      "5. **Sustainability and ESG Investing**: Companies emphasizing environmental, social, and governance (ESG) factors have attracted more investment. Tech companies that demonstrate commitment to sustainability were increasingly favored by investors.\n",
      "\n",
      "6. **Valuation Corrections**: After a boom period, some tech stocks went through corrections as investors reassessed valuations—particularly for growth stocks that were trading at very high price-to-earnings ratios.\n",
      "\n",
      "7. **Interest Rate Impact**: Tech stocks are particularly sensitive to interest rate changes. As central banks adjusted interest rates to combat inflation, growth tech stocks experienced volatility in response to changing borrowing costs.\n",
      "\n",
      "8. **Increased M&A Activity**: There was a notable trend of mergers and acquisitions as companies sought to bolster their technology portfolios and enhance competitive advantages.\n",
      "\n",
      "9. **Remote Work Technologies**: Companies that provide tools and solutions for remote work continued to see growth, even as hybrid work models became standard.\n",
      "\n",
      "Always remember that market conditions can change rapidly, so staying updated with current news, analyses, and expert commentary is critical for making informed decisions.\n",
      "\n",
      "[{'role': 'user', 'content': 'What are the current trends in the tech stock market?'}, {'role': 'assistant', 'content': 'As of my last knowledge update in October 2023, I can provide some general trends that have been observed in the tech stock market leading up to that point. However, for the most current insights, I recommend checking real-time financial news and stock market analysis. Here are some notable trends that were observed:\\n\\n1. **Artificial Intelligence (AI) Boom**: Companies developing AI technologies, particularly those involved in machine learning, natural language processing, and generative AI, saw significant increases in investment and stock prices. Major players like NVIDIA and Microsoft, which have been heavily involved in AI, benefited greatly.\\n\\n2. **Cloud Computing Growth**: Cloud services continued to be a strong driver of growth for tech companies. Firms that offer cloud infrastructure and services (like Amazon AWS, Microsoft Azure, and Google Cloud) have been performing well.\\n\\n3. **Increased Focus on Cybersecurity**: With the rising threats of cyberattacks, cybersecurity stocks gained attention as businesses and governments invested more in protecting their digital assets.\\n\\n4. **Regulatory Scrutiny**: Big Tech faced ongoing scrutiny from regulators regarding antitrust issues, privacy concerns, and data security. This uncertainty has sometimes led to volatility in the share prices of major tech firms.\\n\\n5. **Sustainability and ESG Investing**: Companies emphasizing environmental, social, and governance (ESG) factors have attracted more investment. Tech companies that demonstrate commitment to sustainability were increasingly favored by investors.\\n\\n6. **Valuation Corrections**: After a boom period, some tech stocks went through corrections as investors reassessed valuations—particularly for growth stocks that were trading at very high price-to-earnings ratios.\\n\\n7. **Interest Rate Impact**: Tech stocks are particularly sensitive to interest rate changes. As central banks adjusted interest rates to combat inflation, growth tech stocks experienced volatility in response to changing borrowing costs.\\n\\n8. **Increased M&A Activity**: There was a notable trend of mergers and acquisitions as companies sought to bolster their technology portfolios and enhance competitive advantages.\\n\\n9. **Remote Work Technologies**: Companies that provide tools and solutions for remote work continued to see growth, even as hybrid work models became standard.\\n\\nAlways remember that market conditions can change rapidly, so staying updated with current news, analyses, and expert commentary is critical for making informed decisions.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensaje del sistema\n",
    "base_system_message = \"You are a financial analyst expert.\"\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)\n",
    "\n",
    "# Crear lista de mensajes\n",
    "user_message = \"What are the current trends in the tech stock market?\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = send_message(messages, deployment_name)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)\n",
    "\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Contar Tokens en una Conversación Extendida\n",
    "Enunciado:\n",
    "Dado un conjunto inicial de mensajes, agrega tres mensajes adicionales:\n",
    "\n",
    "\"Explain the impact of inflation on stock prices.\"\n",
    "\"What are the top stocks to watch in 2025?\"\n",
    "\"Summarize the latest market news in 50 words.\"\n",
    "Calcula y muestra el número total de tokens tras añadir cada mensaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count after adding 'Explain the impact of inflation on stock prices.': 48\n",
      "Token count after adding 'What are the top stocks to watch in 2025?': 65\n",
      "Token count after adding 'Summarize the latest market news in 50 words.': 82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensajes iniciales\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in financial topics.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the current trends in the tech stock market?\"}\n",
    "]\n",
    "\n",
    "# Mensajes adicionales\n",
    "additional_messages = [\n",
    "    \"Explain the impact of inflation on stock prices.\",\n",
    "    \"What are the top stocks to watch in 2025?\",\n",
    "    \"Summarize the latest market news in 50 words.\"\n",
    "]\n",
    "\n",
    "# Agregar mensajes y calcular tokens\n",
    "for msg in additional_messages:\n",
    "    messages.append({\"role\": \"user\", \"content\": msg})\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "    print(f\"Token count after adding '{msg}': {token_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Personalizar el Mensaje del Sistema Según el Usuario\n",
    "Enunciado:\n",
    "Escribe un programa que permita al usuario definir el rol de ChatGPT mediante una entrada de texto (input). Una vez definido, responde al mensaje:\n",
    "\"What are your key skills as an assistant?\"\n",
    "Usa el mensaje del sistema definido por el usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are Cocinero top.\n",
      "\n",
      "[USER]\n",
      "What are your key skills as an assistant?\n",
      "\n",
      "[ASSISTANT]\n",
      "As an assistant, my key skills include:\n",
      "\n",
      "1. **Information Retrieval**: I can quickly provide relevant information on a wide range of topics, from cooking techniques to historical facts.\n",
      "\n",
      "2. **Recipe Development**: I can suggest, modify, and create recipes based on specific ingredients, dietary preferences, or cuisine types.\n",
      "\n",
      "3. **Meal Planning**: I can help plan balanced meals, suggest grocery lists, and provide tips for efficient cooking.\n",
      "\n",
      "4. **Time Management**: I can assist in organizing cooking schedules, making meal prep more efficient.\n",
      "\n",
      "5. **Problem-Solving**: I'm equipped to troubleshoot cooking issues, offering solutions for common kitchen problems.\n",
      "\n",
      "6. **Nutritional Guidance**: I can provide insights into the nutritional value of ingredients and suggest healthier alternatives.\n",
      "\n",
      "7. **Creativity**: I can inspire creativity in cooking by suggesting unique flavor pairings or presentation styles.\n",
      "\n",
      "8. **Culinary Techniques**: I can explain various cooking methods and techniques, catering to beginners and experienced cooks alike.\n",
      "\n",
      "9. **Cultural Knowledge**: I can provide insights into different culinary traditions and practices from around the world.\n",
      "\n",
      "10. **Personalization**: I can tailor advice and recommendations based on individual tastes, dietary restrictions, and lifestyle preferences.\n",
      "\n",
      "If you have specific questions or need assistance with something, feel free to ask!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrada del usuario para definir el mensaje del sistema\n",
    "user_defined_role = input(\"Define the role of the assistant: \")\n",
    "system_message = f\"You are {user_defined_role.strip()}.\"\n",
    "\n",
    "# Crear lista de mensajes\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"What are your key skills as an assistant?\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = send_message(messages, deployment_name)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "# Mostrar la conversación\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Crear un Generador de Respuestas Creativo\n",
    "Enunciado:\n",
    "Diseña un programa que permita configurar la creatividad del modelo (temperatura) a través de una entrada del usuario. Una vez configurado, responde a la pregunta:\n",
    "\"Can you suggest an out-of-the-box idea for a startup?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! Here’s an out-of-the-box startup idea: **\"Eco-Lockers: A Sustainable Shared Storage Solution.\"**\n",
      "\n",
      "### Concept:\n",
      "Eco-Lockers would be a network of smart, eco-friendly lockers installed in urban areas, specifically targeting city dwellers who need temporary storage for their belongings while they work, travel, or enjoy leisure activities. \n",
      "\n",
      "### Key Features:\n",
      "1. **Sustainability Focus:** The lockers would be made from recycled materials and powered by renewable energy sources, promoting an eco-friendly approach.\n",
      "\n",
      "2. **Smart Technology:** Users can access lockers via a mobile app, which offers features like real-time availability, booking, and electronic key access. The app also tracks usage patterns for optimizing locker placement.\n",
      "\n",
      "3. **Community Sharing:** Users can rent out their personal storage space when they're not using it, creating a local sharing economy. This could include garages, spare rooms, or unused storage units.\n",
      "\n",
      "4. **Subscription Model:** Offer a subscription service for frequent users, providing them with discounts and exclusive features like priority access or larger locker sizes.\n",
      "\n",
      "5. **Partnerships with Local Businesses:** Collaborate with nearby cafes, grocery stores, or gyms to offer locker services, allowing customers to securely stow belongings while they shop or workout.\n",
      "\n",
      "6. **Educational Component:** Each locker could feature information about local recycling options or tips for reducing waste, fostering community awareness about sustainability.\n",
      "\n",
      "### Market Potential:\n",
      "With the rise of urban living and a growing emphasis on sustainability, Eco-Lockers could cater to a wide audience, including tourists, students, remote workers, and city residents. The ability to provide secure, flexible storage solutions can address common urban challenges related to space and convenience.\n",
      "\n",
      "### Revenue Streams:\n",
      "- Locker rentals (hourly or daily rates)\n",
      "- Subscription services\n",
      "- Partnerships with local businesses for advertising or revenue sharing\n",
      "- Eco-friendly merchandise sales through the app (e.g., reusable bags, containers)\n",
      "\n",
      "### Impact:\n",
      "This startup could enhance urban living by reducing clutter, supporting the sharing economy, and promoting sustainable practices, all while offering a practical service that fills a gap in the market. \n",
      "\n",
      "What do you think of this idea?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrada del usuario para definir la creatividad\n",
    "temperature = float(input(\"Set the creativity level (0.0 - 1.0): \"))\n",
    "if not (0.0 <= temperature <= 1.0):\n",
    "    raise ValueError(\"Creativity level must be between 0.0 and 1.0.\")\n",
    "max_response_tokens=1000\n",
    "\n",
    "# Crear lista de mensajes\n",
    "system_message = \"You are a highly creative assistant.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Can you suggest an out-of-the-box idea for a startup?\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje con creatividad ajustada\n",
    "response = send_message(messages, deployment_name, max_response_tokens, temperature)\n",
    "\n",
    "# Mostrar la respuesta\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Cambiar el Tono del Mensaje\n",
    "Enunciado:\n",
    "Configura el mensaje del sistema para que ChatGPT responda en un tono humorístico y escribe una respuesta al mensaje:\n",
    "\"Explain quantum computing in a funny way.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a humorous assistant.\n",
      "\n",
      "[USER]\n",
      "Explain quantum computing in a funny way.\n",
      "\n",
      "[ASSISTANT]\n",
      "Sure! Imagine you’re trying to find your way out of a giant maze packed with cheese. Classic computers are like a bunch of little mice individually running around, checking every path one at a time, squeaking their findings to each other. They’re efficient and get the job done, but it can take a while—especially if you’re stuck behind a particularly picky cheese-loving mouse who insists on zigzagging!\n",
      "\n",
      "Now, quantum computers are like a group of supercharged, hyper-intelligent mice who decided to learn some tricky dance moves. Instead of running through the maze one by one, they perform a coordinated zig-zagging, flipping, and twirling dance that lets them explore multiple paths at once. It’s as if they’re in a competition to see who can find the cheese first while also making a TikTok video at the same time!\n",
      "\n",
      "These quantum mice are using the weirdness of quantum mechanics—think Schrödinger's cat hanging out with a whole colony of cheese-loving cats—where they can be in many states at once. So, instead of just checking every option like the classic mice, they take a shortcut through the quantum-dimensional cheese space. Sounds great, right? Well, until they get distracted by some laser pointers…\n",
      "\n",
      "So, in short: while classical computers take the scenic route with a nice little map, quantum computers go through a wormhole and arrive at their cheese party faster, though they might also crash the party because they can’t quite tell if they’re invited or not!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensaje del sistema humorístico\n",
    "system_message = \"You are a humorous assistant.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Explain quantum computing in a funny way.\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = send_message(messages, deployment_name)\n",
    "\n",
    "#append assistant response\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Resumir Mensajes Previos\n",
    "Enunciado:\n",
    "Dado un historial de conversación de 5 mensajes, crea una función que resuma el contenido de los mensajes del usuario en una sola oración.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User messages summary: AI encompasses various technologies, including machine learning, which uses algorithms to learn from data; neural networks, which are computational models inspired by the human brain; and deep learning, a subset of machine learning with applications in areas like image recognition, natural language processing, and autonomous systems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Historial de mensajes\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about AI.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How does machine learning work?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you explain neural networks?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the applications of deep learning?\"}\n",
    "]\n",
    "\n",
    "# Resumir mensajes del usuario\n",
    "def summarize_user_messages(messages):\n",
    "    user_messages = [msg['content'] for msg in messages if msg['role'] == 'user']\n",
    "    summary_prompt = \"Summarize the following messages into one sentence: \" + \" \".join(user_messages)\n",
    "    summary = send_message([{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                            {\"role\": \"user\", \"content\": summary_prompt}], deployment_name)\n",
    "    return summary\n",
    "\n",
    "# Obtener y mostrar el resumen\n",
    "summary = summarize_user_messages(messages)\n",
    "print(f\"User messages summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Configuración de Temperatura y Tono\n",
    "Enunciado:\n",
    "Escribe un programa que cambie la configuración de temperatura a 0.9 para obtener respuestas más creativas y responde al mensaje:\n",
    "\"Suggest a unique title for a blog about AI in education.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Learning Reimagined: The AI Revolution in Education\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensajes iniciales\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a creative assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Suggest a unique title for a blog about AI in education.\"}\n",
    "]\n",
    "\n",
    "# temperatura\n",
    "temperature = 0.9\n",
    "\n",
    "# Ajustar temperatura y enviar mensaje\n",
    "response = send_message(messages, deployment_name, max_response_tokens, temperature)\n",
    "\n",
    "# Mostrar la respuesta\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
