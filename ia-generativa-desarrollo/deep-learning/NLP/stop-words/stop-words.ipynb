{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  FASE 1: ANÁLISIS INICIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1.1 – Cargar el CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El paquete llegó con el embalaje comprometido,...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Después de 3 semanas de espera, el artículo nu...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La atención al cliente fue evasiva y poco reso...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entrega express y producto en perfecto estado....</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El sistema de seguimiento en línea mostró info...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto  etiqueta\n",
       "0  El paquete llegó con el embalaje comprometido,...   neutral\n",
       "1  Después de 3 semanas de espera, el artículo nu...  negativo\n",
       "2  La atención al cliente fue evasiva y poco reso...  negativo\n",
       "3  Entrega express y producto en perfecto estado....  positivo\n",
       "4  El sistema de seguimiento en línea mostró info...  negativo"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar CSV\n",
    "import pandas as pd\n",
    "\n",
    "def cargar_csv_formato_resenas(path):\n",
    "    textos = []\n",
    "    etiquetas = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        next(f)  # saltar encabezado\n",
    "        for linea in f:\n",
    "            partes = linea.strip().rsplit(\",\", 1)  # dividir por última coma\n",
    "            if len(partes) == 2:\n",
    "                texto, etiqueta = partes\n",
    "                textos.append(texto.strip())\n",
    "                etiquetas.append(etiqueta.strip())\n",
    "    return pd.DataFrame({\"texto\": textos, \"etiqueta\": etiquetas})\n",
    "\n",
    "df = cargar_csv_formato_resenas(\"comentarios_clientes.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texto       0\n",
      "etiqueta    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver resumen de valores faltantes por columna\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               texto  etiqueta  \\\n",
      "0  El paquete llegó con el embalaje comprometido,...   neutral   \n",
      "1  Después de 3 semanas de espera, el artículo nu...  negativo   \n",
      "2  La atención al cliente fue evasiva y poco reso...  negativo   \n",
      "3  Entrega express y producto en perfecto estado....  positivo   \n",
      "4  El sistema de seguimiento en línea mostró info...  negativo   \n",
      "5  Materiales de calidad inferior a lo descrito e...  negativo   \n",
      "6  El proceso de devolución resultó engorroso por...  negativo   \n",
      "7  Artículo funcional pero con manual de instrucc...   neutral   \n",
      "8  Demoras recurrentes en la actualización del es...  negativo   \n",
      "9  Embalaje ecológico y resistente que protegió b...  positivo   \n",
      "\n",
      "  eliminadas_criticas  cambio_significado  \n",
      "0            [aunque]                True  \n",
      "1             [nunca]                True  \n",
      "2                  []               False  \n",
      "3                  []               False  \n",
      "4                  []               False  \n",
      "5                  []               False  \n",
      "6                  []               False  \n",
      "7              [pero]                True  \n",
      "8                  []               False  \n",
      "9                  []               False  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar modelo spaCy en español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Palabras cuya eliminación podría alterar el significado\n",
    "# Detectar solo las críticas dentro del set completo de stopwords\n",
    "stopwords_spacy = nlp.Defaults.stop_words\n",
    "stopwords_criticas = {w for w in stopwords_spacy if w in {\"no\", \"nunca\", \"tampoco\", \"pero\", \"aunque\", \"sin embargo\"}}\n",
    "\n",
    "\n",
    "# Función que evalúa si se eliminó una stopword crítica\n",
    "def analizar_stopwords_criticas(fila):\n",
    "    texto = fila[\"texto\"]\n",
    "    etiqueta = fila[\"etiqueta\"]\n",
    "    doc = nlp(texto)\n",
    "    eliminadas = [t.text.lower() for t in doc if t.is_stop]\n",
    "    eliminadas_criticas = [pal for pal in eliminadas if pal in stopwords_criticas]\n",
    "    return {\n",
    "        \"texto\": texto,\n",
    "        \"etiqueta\": etiqueta,\n",
    "        \"eliminadas_criticas\": eliminadas_criticas,\n",
    "        \"cambio_significado\": len(eliminadas_criticas) > 0\n",
    "    }\n",
    "\n",
    "# Aplicar a todo el dataset\n",
    "resultados_df = df.apply(analizar_stopwords_criticas, axis=1, result_type=\"expand\")\n",
    "\n",
    "# Mostrar tabla de verificación\n",
    "tabla_verificacion = resultados_df[[\"texto\", \"etiqueta\", \"eliminadas_criticas\", \"cambio_significado\"]]\n",
    "print(tabla_verificacion.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2: Personalización de la Lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alumno_AI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo 1\n",
      "Original: El paquete llegó con el embalaje comprometido, aunque lograron reembolsarme rápidamente\n",
      "Filtrado: ['paquete', 'llegó', 'embalaje', 'comprometido', 'aunque', 'lograron', 'reembolsarme', 'rápidamente']\n",
      "\n",
      "Ejemplo 2\n",
      "Original: La atención al cliente fue evasiva y poco resolutiva en mi reclamo\n",
      "Filtrado: ['atención', 'evasiva', 'resolutiva', 'reclamo']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Asegurarse de tener los recursos de nltk descargados\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Cargar spaCy y nltk stopwords\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "stopwords_nltk = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "# Paso 1: Tokenizar y contar frecuencia de palabras\n",
    "todas_las_palabras = []\n",
    "for texto in df[\"texto\"]:\n",
    "    tokens = [token.text.lower() for token in nlp(texto) if token.is_alpha]\n",
    "    todas_las_palabras.extend(tokens)\n",
    "\n",
    "frecuencia = Counter(todas_las_palabras)\n",
    "\n",
    "# Paso 2: Construir stopwords personalizadas\n",
    "stopwords_personalizadas = stopwords_nltk.copy()\n",
    "\n",
    "# 2.1 – Eliminar términos clave que deben conservarse\n",
    "terminos_a_conservar = {\"no\", \"nunca\", \"tampoco\", \"pero\", \"aunque\", \"sin embargo\"}\n",
    "stopwords_personalizadas -= terminos_a_conservar\n",
    "\n",
    "# 2.2 – Añadir términos genéricos redundantes y no informativos\n",
    "t_terminos_genericos = {\"producto\", \"cliente\", \"día\", \"hacer\", \"tener\", \"decir\", \"pd\"}\n",
    "stopwords_personalizadas |= t_terminos_genericos\n",
    "\n",
    "# 2.3 – Añadir palabras como \"hola\" y \"gracias\" si aparecen en el texto usando regex\n",
    "terminos_regex = re.compile(r\"\\b(hola|gracias)\\b\", flags=re.IGNORECASE)\n",
    "for texto in df[\"texto\"]:\n",
    "    if terminos_regex.search(texto):\n",
    "        for palabra in [\"hola\", \"gracias\"]:\n",
    "            stopwords_personalizadas.add(palabra)\n",
    "\n",
    "# Función para limpiar texto usando la lista personalizada\n",
    "def limpiar_con_stopwords_personalizadas(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens_filtrados = [\n",
    "        t.text.lower() for t in doc\n",
    "        if t.text.lower() not in stopwords_personalizadas and t.is_alpha\n",
    "    ]\n",
    "    return tokens_filtrados\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(\"Ejemplo 1\")\n",
    "ejemplo = df[\"texto\"].iloc[0]\n",
    "print(\"Original:\", ejemplo)\n",
    "print(\"Filtrado:\", limpiar_con_stopwords_personalizadas(ejemplo))\n",
    "\n",
    "print(\"\\nEjemplo 2\")\n",
    "ejemplo = df[\"texto\"].iloc[2]\n",
    "print(\"Original:\", ejemplo)\n",
    "print(\"Filtrado:\", limpiar_con_stopwords_personalizadas(ejemplo))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 3: Implementación y Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alumno_AI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Casos de Prueba:\n",
      "\n",
      "Texto 1:\n",
      "  Original: No funciona bien, pero el diseño es bonito.\n",
      "  Tokens procesados: ['no', 'funciona', 'bien', 'pero', 'diseño', 'bonito']\n",
      "  Esperado: ['no', 'funciona', 'bien', 'pero', 'diseño', 'bonito']\n",
      "  ✅ Correcto: True\n",
      "\n",
      "Texto 2:\n",
      "  Original: Nunca compré algo tan malo. Aunque el precio es bajo, no lo vale.\n",
      "  Tokens procesados: ['nunca', 'compré', 'malo', 'aunque', 'precio', 'bajo', 'no', 'vale']\n",
      "  Esperado: ['nunca', 'compré', 'malo', 'aunque', 'precio', 'bajo', 'no', 'vale']\n",
      "  ✅ Correcto: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Asegurar descarga de stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Cargar modelo y stopwords base\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "stopwords_es = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "# Quitar términos críticos que deben preservarse\n",
    "terminos_clave = {\"no\", \"nunca\", \"tampoco\", \"pero\", \"aunque\", \"sin embargo\"}\n",
    "stopwords_es -= terminos_clave\n",
    "\n",
    "# Añadir términos no informativos y genéricos\n",
    "stopwords_es |= {\"producto\", \"cliente\", \"día\", \"hacer\", \"tener\", \"decir\", \"hola\", \"gracias\", \"pd\", \"tan\"}\n",
    "\n",
    "# Función de procesamiento\n",
    "def procesar_texto(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens = [\n",
    "        token.text.lower()\n",
    "        for token in doc\n",
    "        if token.is_alpha and token.text.lower() not in stopwords_es\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "# Casos de prueba\n",
    "casos = {\n",
    "    \"Texto 1\": \"No funciona bien, pero el diseño es bonito.\",\n",
    "    \"Texto 2\": \"Nunca compré algo tan malo. Aunque el precio es bajo, no lo vale.\"\n",
    "}\n",
    "\n",
    "# Resultados esperados\n",
    "esperados = {\n",
    "    \"Texto 1\": [\"no\", \"funciona\", \"bien\", \"pero\", \"diseño\", \"bonito\"],\n",
    "    \"Texto 2\": [\"nunca\", \"compré\", \"malo\", \"aunque\", \"precio\", \"bajo\", \"no\", \"vale\"]\n",
    "}\n",
    "\n",
    "# Prueba\n",
    "print(\"Resultados de Casos de Prueba:\\n\")\n",
    "for nombre, texto in casos.items():\n",
    "    tokens = procesar_texto(texto)\n",
    "    print(f\"{nombre}:\\n  Original: {texto}\\n  Tokens procesados: {tokens}\")\n",
    "    print(f\"  Esperado: {esperados[nombre]}\")\n",
    "    print(f\"  ✅ Correcto: {tokens == esperados[nombre]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 4: Evaluación de Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy SIN stopwords personalizadas: 0.53\n",
      "Accuracy CON stopwords personalizadas: 0.40\n",
      "\n",
      "Muestras con diferencias de predicción:\n",
      "                                             original  \\\n",
      "7   Experiencia unboxing premium con empaque de di...   \n",
      "11  El sistema de seguimiento en línea mostró info...   \n",
      "\n",
      "                                             filtrado  etiqueta  \\\n",
      "7   experiencia unboxing premium empaque diseño cu...  positivo   \n",
      "11  sistema seguimiento línea mostró información i...  negativo   \n",
      "\n",
      "   pred_sin_personalizadas pred_con_personalizadas  \n",
      "7                 positivo                negativo  \n",
      "11                negativo                positivo  \n",
      "\n",
      "🔍 Análisis de impacto:\n",
      "  ✅ Mejoraron con stopwords personalizadas: 0\n",
      "  ❌ Empeoraron con stopwords personalizadas: 2\n",
      "  ➖ Sin cambios en la predicción: 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar modelo spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Crear lista personalizada de stopwords\n",
    "stopwords_es = nlp.Defaults.stop_words.copy()\n",
    "terminos_a_conservar = {\"no\", \"nunca\", \"tampoco\", \"pero\", \"aunque\", \"sin embargo\"}\n",
    "stopwords_adicionales = {\"producto\", \"cliente\", \"día\", \"hacer\", \"tener\", \"decir\", \"hola\", \"gracias\", \"pd\"}\n",
    "\n",
    "for palabra in terminos_a_conservar:\n",
    "    stopwords_es.discard(palabra)\n",
    "stopwords_es.update(stopwords_adicionales)\n",
    "\n",
    "# Función para limpiar texto con stopwords personalizadas\n",
    "def limpiar_con_stopwords(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens = [token.text.lower() for token in doc if token.is_alpha and token.text.lower() not in stopwords_es]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Aplicar limpieza al dataset\n",
    "df_filtrado = df.copy()\n",
    "df_filtrado[\"texto_filtrado\"] = df_filtrado[\"texto\"].apply(limpiar_con_stopwords)\n",
    "\n",
    "# Submuestreo si es necesario\n",
    "df_sub = df_filtrado.sample(n=200, random_state=42) if len(df_filtrado) > 200 else df_filtrado\n",
    "\n",
    "# ----------- MODELO BASE (sin stopwords personalizadas) -----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_sub[\"texto\"], df_sub[\"etiqueta\"], test_size=0.3, random_state=42)\n",
    "\n",
    "vectorizer_std = CountVectorizer(max_features=1000)\n",
    "X_train_vec = vectorizer_std.fit_transform(X_train)\n",
    "X_test_vec = vectorizer_std.transform(X_test)\n",
    "\n",
    "modelo_std = LogisticRegression(max_iter=1000)\n",
    "modelo_std.fit(X_train_vec, y_train)\n",
    "preds_std = modelo_std.predict(X_test_vec)\n",
    "acc_std = accuracy_score(y_test, preds_std)\n",
    "\n",
    "# ----------- MODELO PERSONALIZADO (con stopwords personalizadas) -----------\n",
    "X_train_f, X_test_f, _, _ = train_test_split(df_sub[\"texto_filtrado\"], df_sub[\"etiqueta\"], test_size=0.3, random_state=42)\n",
    "\n",
    "vectorizer_custom = CountVectorizer(max_features=1000)\n",
    "X_train_vec_f = vectorizer_custom.fit_transform(X_train_f)\n",
    "X_test_vec_f = vectorizer_custom.transform(X_test_f)\n",
    "\n",
    "modelo_custom = LogisticRegression(max_iter=1000)\n",
    "modelo_custom.fit(X_train_vec_f, y_train)\n",
    "preds_custom = modelo_custom.predict(X_test_vec_f)\n",
    "acc_custom = accuracy_score(y_test, preds_custom)\n",
    "\n",
    "# ----------- RESULTADOS -----------\n",
    "\n",
    "print(f\"\\nAccuracy SIN stopwords personalizadas: {acc_std:.2f}\")\n",
    "print(f\"Accuracy CON stopwords personalizadas: {acc_custom:.2f}\")\n",
    "\n",
    "# Comparación de predicciones\n",
    "comparacion = pd.DataFrame({\n",
    "    \"original\": X_test.values,\n",
    "    \"filtrado\": X_test_f.values,\n",
    "    \"etiqueta\": y_test.values,\n",
    "    \"pred_sin_personalizadas\": preds_std,\n",
    "    \"pred_con_personalizadas\": preds_custom\n",
    "})\n",
    "\n",
    "diferencias = comparacion[comparacion[\"pred_sin_personalizadas\"] != comparacion[\"pred_con_personalizadas\"]]\n",
    "print(\"\\nMuestras con diferencias de predicción:\")\n",
    "print(diferencias.head())\n",
    "\n",
    "# Análisis de impacto\n",
    "mejoraron = ((preds_std != y_test) & (preds_custom == y_test)).sum()\n",
    "empeoraron = ((preds_std == y_test) & (preds_custom != y_test)).sum()\n",
    "sin_cambios = (preds_std == preds_custom).sum()\n",
    "\n",
    "print(f\"\\n🔍 Análisis de impacto:\")\n",
    "print(f\"  ✅ Mejoraron con stopwords personalizadas: {mejoraron}\")\n",
    "print(f\"  ❌ Empeoraron con stopwords personalizadas: {empeoraron}\")\n",
    "print(f\"  ➖ Sin cambios en la predicción: {sin_cambios}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar lista de stopwords personalizadas en un archivo .txt\n",
    "with open(\"stopwords_personalizadas.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for palabra in sorted(stopwords_es):\n",
    "        f.write(palabra + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
